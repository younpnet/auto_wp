import requests
import json
import time
import base64
import re
import os
import io
import random
from datetime import datetime


# ì´ë¯¸ì§€ ì²˜ë¦¬ë¥¼ ìœ„í•œ PIL ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    from PIL import Image
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False
    print("âš ï¸ ê²½ê³ : PIL(Pillow) ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")


# ==============================================================================
# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
# ==============================================================================
CONFIG = {
    "GEMINI_API_KEY": os.environ.get("GEMINI_API_KEY", ""),
    "WP_URL": os.environ.get("WP_URL", "").rstrip("/"),
    "WP_USERNAME": os.environ.get("WP_USERNAME", "admin"),
    "WP_APP_PASSWORD": os.environ.get("WP_APP_PASSWORD", ""),
    "TEXT_MODEL": "gemini-2.5-flash-preview-09-2025",
    "IMAGE_MODEL": "imagen-4.0-generate-001",
    "NAVER_CLIENT_ID": os.environ.get("NAVER_CLIENT_ID", ""),
    "NAVER_CLIENT_SECRET": os.environ.get("NAVER_CLIENT_SECRET", "")
}


class WordPressAutoPoster:
    def __init__(self):
        user_pass = f"{CONFIG['WP_USERNAME']}:{CONFIG['WP_APP_PASSWORD']}"
        self.auth = base64.b64encode(user_pass.encode()).decode()
        self.headers = {"Authorization": f"Basic {self.auth}"}

        # 1. ì™¸ë¶€ ë§í¬ 2ê°œ ë¡œë“œ
        self.external_links = self.load_external_links(2)
        # 2. ë‚´ë¶€ ë§í¬ 2ê°œìš© ìµœê·¼ ë°œí–‰ê¸€ ë¡œë“œ
        self.internal_link_pool = self.fetch_internal_link_pool(15)
        # 3. ì¤‘ë³µ ë°©ì§€ìš© ì œëª© ë¦¬ìŠ¤íŠ¸
        self.recent_titles = [post['title'] for post in self.internal_link_pool]


    def fetch_internal_link_pool(self, count=15):
        url = f"{CONFIG['WP_URL']}/wp-json/wp/v2/posts"
        params = {"per_page": count, "status": "publish", "_fields": "title,link"}
        try:
            res = requests.get(url, headers=self.headers, params=params, timeout=20)
            if res.status_code == 200:
                return [{"title": re.sub('<.*?>', '', post['title']['rendered']).strip(), "url": post['link'].strip()} for post in res.json()]
        except: pass
        return []


    def load_external_links(self, count=2):
        try:
            if os.path.exists('links.json'):
                with open('links.json', 'r', encoding='utf-8') as f:
                    links = json.load(f)
                    return random.sample(links, min(len(links), count))
        except: pass
        return []


    def get_or_create_tag_ids(self, tags_input):
        if not tags_input: return []
        tag_names = [t.strip() for t in tags_input.split(',')]
        tag_ids = []
        for name in tag_names:
            try:
                search_url = f"{CONFIG['WP_URL']}/wp-json/wp/v2/tags?search={name}"
                res = requests.get(search_url, headers=self.headers)
                existing = res.json()
                match = next((t for t in existing if t['name'].lower() == name.lower()), None)
                if match:
                    tag_ids.append(match['id'])
                else:
                    create_res = requests.post(f"{CONFIG['WP_URL']}/wp-json/wp/v2/tags", 
                                             headers=self.headers, json={"name": name})
                    if create_res.status_code == 201: tag_ids.append(create_res.json()['id'])
            except: continue
        return tag_ids


    def search_naver_news(self):
        queries = ["êµ­ë¯¼ì—°ê¸ˆ ìˆ˜ë ¹ì•¡ ì¦ëŒ€ ê¿€íŒ", "2026 êµ­ë¯¼ì—°ê¸ˆ ê°œì • ì†Œì‹", "ë…¸í›„ ì¤€ë¹„ í•„ìˆ˜ ìƒì‹"]
        query = random.choice(queries)
        url = "https://openapi.naver.com/v1/search/news.json"
        headers = {"X-Naver-Client-Id": CONFIG["NAVER_CLIENT_ID"], "X-Naver-Client-Secret": CONFIG["NAVER_CLIENT_SECRET"]}
        params = {"query": query, "display": 12, "sort": "sim"}
        try:
            res = requests.get(url, headers=headers, params=params, timeout=20)
            if res.status_code == 200:
                return "\n".join([f"- {re.sub('<.*?>', '', i['title'])}: {re.sub('<.*?>', '', i['description'])}" for i in res.json().get('items', [])])
        except: return "êµ­ë¯¼ì—°ê¸ˆ ìµœì‹  ì´ìŠˆ ë¸Œë¦¬í•‘"
        return ""


    def generate_image(self, title, excerpt):
        print(f"ğŸ¨ ì´ë¯¸ì§€ ìƒì„± ì¤‘: {title}")
        url = f"https://generativelanguage.googleapis.com/v1beta/models/{CONFIG['IMAGE_MODEL']}:predict?key={CONFIG['GEMINI_API_KEY']}"
        image_prompt = (
            f"Professional and warm lifestyle photography for a Korean finance blog. "
            f"Subject: A happy South Korean elderly couple in their 70s, "
            f"smiling in a luxurious and bright modern Korean home. "
            f"Style: Photorealistic, cinematic lighting, high quality, 16:9, NO TEXT."
        )
        payload = {"instances": [{"prompt": image_prompt}], "parameters": {"sampleCount": 1}}
        try:
            res = requests.post(url, json=payload, timeout=120)
            if res.status_code == 200: return res.json()['predictions'][0]['bytesBase64Encoded']
        except: pass
        return None


    def upload_media(self, img_b64):
        if not img_b64: return None
        raw_data = base64.b64decode(img_b64)
        if PIL_AVAILABLE:
            try:
                img = Image.open(io.BytesIO(raw_data)).convert('RGB')
                out = io.BytesIO()
                img.save(out, format="JPEG", quality=70, optimize=True)
                raw_data = out.getvalue()
            except: pass
        files = {'file': (f"nps_pro_{int(time.time())}.jpg", raw_data, "image/jpeg")}
        res = requests.post(f"{CONFIG['WP_URL']}/wp-json/wp/v2/media", headers=self.headers, files=files, timeout=60)
        return res.json().get('id') if res.status_code == 201 else None


    def extract_and_validate_url(self, url_string):
        """URL ë¬¸ìì—´ì—ì„œ ìœ íš¨í•œ URLë§Œ ì¶”ì¶œí•˜ê³  ê²€ì¦í•©ë‹ˆë‹¤."""
        if not url_string:
            return ""

        # ì—¬ëŸ¬ ê°œì˜ https:// ê°€ ìˆìœ¼ë©´ ë§ˆì§€ë§‰ ê²ƒë§Œ ì„ íƒ
        urls = re.findall(r'https?://[^\s"<>]+', url_string)
        if urls:
            url = urls[-1]
        else:
            url = url_string

        # URLì´ https://ë¡œ ì‹œì‘í•˜ì§€ ì•Šìœ¼ë©´ ë¹ˆ ë¬¸ìì—´ ë°˜í™˜
        if not url.startswith('http://') and not url.startswith('https://'):
            return ""

        return url


    def clean_content(self, content):
        """ë³¸ë¬¸ ë‚´ ì¤‘ë³µ, ë¶ˆí•„ìš” ì£¼ì„ ë° ê¹¨ì§„ í•˜ì´í¼ë§í¬ íŒ¨í„´ì„ ë¬¼ë¦¬ì ìœ¼ë¡œ ì œê±°í•©ë‹ˆë‹¤."""
        if not content: return ""

        # 1. AI ê°€ì§œ ì£¼ì„ ì œê±°
        content = re.sub(r'//\s*[a-zA-Zê°€-í£]+', '', content)
        content = content.replace('```html', '').replace('```', '')

        # 2. í•˜ì´í¼ë§í¬ ë‚´ ë„ë©”ì¸ ì¤‘ë³µ ë° ê²½ë¡œ íŒŒí¸ ê°•ì œ êµì • (ëŒ€í­ ê°•í™”)
        def repair_links(match):
            url = match.group(1)

            # 2-1. ìœ íš¨í•œ URLë§Œ ì¶”ì¶œ
            url = self.extract_and_validate_url(url)
            if not url:
                return f'href="#"'  # ìœ íš¨í•˜ì§€ ì•Šì€ URLì€ #ìœ¼ë¡œ ëŒ€ì²´

            # 2-2. URL íŒŒì‹±í•˜ì—¬ ë„ë©”ì¸ê³¼ ê²½ë¡œ ë¶„ë¦¬
            url_match = re.match(r'(https?://[^/]+)(.*)', url)
            if not url_match:
                return f'href="{url}"'

            domain = url_match.group(1)
            path = url_match.group(2) if url_match.group(2) else ""

            # 2-3. ê²½ë¡œì—ì„œ ë„ë©”ì¸ íŒŒí¸ ì œê±°
            # ì˜ˆ: /.net/ ê°™ì€ TLD íŒŒí¸ ì œê±°
            path = re.sub(r'/\.[a-z]{2,}/', '/', path)

            # 2-4. ê²½ë¡œì— ë‹¤ë¥¸ ë„ë©”ì¸ì´ í¬í•¨ëœ ê²½ìš° ì œê±°
            # ì˜ˆ: /ê²½ë¡œ/-pension.sleepyourmoney.net â†’ /ê²½ë¡œ/
            path = re.sub(r'/[^/]*\.[a-z]{2,}(?:/|$)', '/', path)

            # 2-5. ê²½ë¡œì—ì„œ ë„ë©”ì¸ ìì²´ê°€ ë°˜ë³µë˜ëŠ” ê²½ìš° ì œê±°
            domain_name = domain.replace('https://', '').replace('http://', '')
            if domain_name in path:
                path = re.sub(f'/{re.escape(domain_name)}/?', '/', path)

            # 2-6. ì—°ì†ëœ ìŠ¬ë˜ì‹œ ì •ë¦¬
            path = re.sub(r'/+', '/', path)

            # 2-7. ê²½ë¡œê°€ ì—†ê±°ë‚˜ /ë§Œ ìˆìœ¼ë©´ ì œê±°
            if path in ['', '/']:
                path = ''

            # 2-8. ìµœì¢… URL ì¬êµ¬ì„±
            clean_url = f"{domain}{path}"

            # 2-9. URL ëì˜ ë¶ˆí•„ìš”í•œ ìŠ¬ë˜ì‹œ ì œê±° (ë£¨íŠ¸ ê²½ë¡œ ì œì™¸)
            if clean_url.endswith('/') and clean_url != f"{domain}/":
                clean_url = clean_url.rstrip('/')

            return f'href="{clean_url}"'

        content = re.sub(r'href="([^"]+)"', repair_links, content)

        # 3. ë¦¬ìŠ¤íŠ¸ ë¸”ë¡ ë³‘í•© ë° ë¬¸ì¥ ë°˜ë³µ ì œê±°
        content = re.sub(r'</ul>\s*<!-- /wp:list -->\s*<!-- wp:list -->\s*<ul>', '', content, flags=re.DOTALL)

        blocks = re.split(r'(<!-- wp:[^>]+-->)', content)
        seen_fingerprints = set()
        refined_output = []
        for i in range(len(blocks)):
            segment = blocks[i]
            if segment.startswith('<!-- wp:') or segment.startswith('<!-- /wp:'):
                refined_output.append(segment)
                continue
            text_only = re.sub(r'<[^>]+>', '', segment).strip()
            if len(text_only) > 15:
                fingerprint = re.sub(r'[^ê°€-í£]', '', text_only)[:120]
                if fingerprint in seen_fingerprints:
                    if refined_output and refined_output[-1].startswith('<!-- wp:'): refined_output.pop()
                    continue
                seen_fingerprints.add(fingerprint)
            refined_output.append(segment)

        final_content = "".join(refined_output).strip()
        # ë™ì¼ êµ¬ì ˆ ë¬´í•œ ë°˜ë³µ íŒ¨í„´ ë¬¼ë¦¬ì  ì œê±°
        final_content = re.sub(r'(([ê°€-í£\s\d,.\(\)]{10,})\s*)\2{2,}', r'\1', final_content)
        return final_content


    def call_gemini(self, prompt, system_instruction):
        url = f"https://generativelanguage.googleapis.com/v1beta/models/{CONFIG['TEXT_MODEL']}:generateContent?key={CONFIG['GEMINI_API_KEY']}"
        payload = {
            "contents": [{"parts": [{"text": prompt}]}],
            "systemInstruction": {"parts": [{"text": system_instruction}]},
            "generationConfig": {
                "responseMimeType": "application/json",
                "temperature": 0.7,
                "maxOutputTokens": 8192,
                "responseSchema": {
                    "type": "OBJECT",
                    "properties": {
                        "title": {"type": "string"},
                        "content": {"type": "string"},
                        "excerpt": {"type": "string"},
                        "tags": {"type": "string"}
                    },
                    "required": ["title", "content", "excerpt", "tags"]
                }
            }
        }
        try:
            res = requests.post(url, json=payload, timeout=300)
            if res.status_code == 200:
                return json.loads(res.json()['candidates'][0]['content']['parts'][0]['text'])
        except Exception as e:
            print(f"âŒ AI ì˜¤ë¥˜: {e}")
        return None


    def generate_post(self):
        print(f"--- [{datetime.now().strftime('%H:%M:%S')}] ìµœì¢… ë§í¬ ë³´í˜¸ ëª¨ë“œ ê°€ë™ ---")
        news = self.search_naver_news()

        # ì™¸ë¶€/ë‚´ë¶€ ë§í¬ ë§¤í•‘ ë°ì´í„° ìƒì„± (íŠ¹ìˆ˜ ê¸°í˜¸ ê¸°ë°˜ í† í° ì‚¬ìš©)
        int_links = random.sample(self.internal_link_pool, min(len(self.internal_link_pool), 2))
        links_mapping = {}
        link_instr_list = []

        for i, link in enumerate(self.external_links):
            token = f"EXTLINK{i}TOKEN"  # ë” ë‹¨ìˆœí•œ í† í°ìœ¼ë¡œ ë³€ê²½
            links_mapping[token] = link['url']
            link_instr_list.append(f"- ì œëª©: {link['title']}, ì‚½ì…ì½”ë“œ: {token} (ì™¸ë¶€ì¶”ì²œ)")

        for i, link in enumerate(int_links):
            token = f"INTLINK{i}TOKEN"  # ë” ë‹¨ìˆœí•œ í† í°ìœ¼ë¡œ ë³€ê²½
            links_mapping[token] = link['url']
            link_instr_list.append(f"- ì œëª©: {link['title']}, ì‚½ì…ì½”ë“œ: {token} (ë‚´ë¶€ì°¸ê³ )")

        link_instruction = "\n".join(link_instr_list)

        system = f"""ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ìµœê³ ì˜ ê¸ˆìœµ ìì‚°ê´€ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 2026ë…„ ì‹œì ì˜ í†µì°°ë ¥ ìˆëŠ” ì „ë¬¸ê°€ ì¹¼ëŸ¼ì„ ì‘ì„±í•˜ì„¸ìš”.


[âš ï¸ í•˜ì´í¼ë§í¬ ì‚½ì… ì ˆëŒ€ ìˆ˜ì¹™ - 4ê°œ í•„ìˆ˜ ì‚½ì…]
1. ë³¸ë¬¸ì— ì•„ë˜ 4ê°œì˜ ì‚½ì…ì½”ë“œë¥¼ ë°˜ë“œì‹œ <a> íƒœê·¸ì˜ href ê°’ìœ¼ë¡œ í¬í•¨í•˜ì„¸ìš”:
{link_instruction}

2. **ì ˆëŒ€ ê¸ˆê¸° ì‚¬í•­**:
   - ì‚½ì…ì½”ë“œ ì•ë’¤ì— ì–´ë–¤ ë¬¸ìë„ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš” (/, -, https:// ë“± ê¸ˆì§€)
   - ì‚½ì…ì½”ë“œë¥¼ ìˆ˜ì •í•˜ê±°ë‚˜ ë³€í˜•í•˜ì§€ ë§ˆì„¸ìš”
   - ë‚˜ìœ ì˜ˆ: <a href="https://example.com/INTLINK0TOKEN">
   - ë‚˜ìœ ì˜ˆ: <a href="/INTLINK0TOKEN">
   - ë‚˜ìœ ì˜ˆ: <a href="-INTLINK0TOKEN">
   - ì¢‹ì€ ì˜ˆ: <a href="INTLINK0TOKEN">

3. ë§í¬ ì‚¬ìš©ë²•:
   - href ì†ì„±ì— ì‚½ì…ì½”ë“œë§Œ ì •í™•íˆ ì…ë ¥: <a href="INTLINK0TOKEN" target="_self">ë§í¬í…ìŠ¤íŠ¸</a>
   - ëª¨ë“  ë§í¬ì— target="_self" ì†ì„± í¬í•¨


[âš ï¸ í•„ìˆ˜: ë¬¸ì„œ êµ¬ì¡° ë° í’ˆì§ˆ]
1. ê³„ì¸µ êµ¬ì¡°: ë°˜ë“œì‹œ h2, h3, h4 ì œëª© ë¸”ë¡ì„ ì‚¬ìš©í•˜ì—¬ ë…¼ë¦¬ì ìœ¼ë¡œ ì„¹ì…˜ì„ ë‚˜ëˆ„ì„¸ìš”. ëª¨ë“  ì„¹ì…˜ì€ ì œëª© ë¸”ë¡ìœ¼ë¡œ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤.
2. ê°€ë…ì„±: í•œ ë¬¸ë‹¨(p íƒœê·¸)ì€ 4~6ë¬¸ì¥ìœ¼ë¡œ êµ¬ì„±í•˜ì„¸ìš”.
3. ì¤‘ë³µ ë°©ì§€: ë™ì¼ ë¬¸ì¥ì´ë‚˜ ë‚´ìš©ì„ ì ˆëŒ€ ë°˜ë³µí•˜ì§€ ë§ˆì„¸ìš”.


[ë³¸ë¬¸ êµ¬ì„±]
- ì œëª© ë§¨ ì•ì— ì—°ë„ë¥¼ ë„£ì§€ ë§ˆì„¸ìš”. ì—°ë„ëŠ” ì œëª© ëì— ë°°ì¹˜í•˜ì„¸ìš”.
- 3,000ì ì´ìƒì˜ ì••ë„ì ì¸ ì •ë³´ëŸ‰ê³¼ ì‹¤ì§ˆì ì¸ ë„ì›€ì„ ì£¼ëŠ” ì¡°ì–¸ì„ í¬í•¨í•˜ì„¸ìš”."""


        post_data = self.call_gemini(f"ë‰´ìŠ¤ ì†ŒìŠ¤:\n{news}\n\nìœ„ ë°ì´í„°ë¥¼ í™œìš©í•´ ë§í¬ ì½”ë“œê°€ ì•ˆì „í•˜ê²Œ ë°°ì¹˜ëœ ê³ í’ˆì§ˆ ì¹¼ëŸ¼ì„ ì‘ì„±í•´ì¤˜.", system)

        if not post_data or not post_data.get('content'):
            print("âŒ ìƒì„± ì‹¤íŒ¨")
            return


        # [í•µì‹¬ ë‹¨ê³„ 1] AIê°€ ìƒì„±í•œ ëª¨ë“  ì˜ëª»ëœ íŒ¨í„´ ì‚¬ì „ ì œê±°
        final_content = post_data['content']

        for token in links_mapping.keys():
            # íŒ¨í„´ 1: ë„ë©”ì¸/ê²½ë¡œ/í† í° í˜•íƒœ ì œê±°
            final_content = re.sub(
                rf'href="https?://[^"]*[/\-]{re.escape(token)}"',
                f'href="{token}"',
                final_content
            )
            # íŒ¨í„´ 2: ìƒëŒ€ê²½ë¡œ/í† í° í˜•íƒœ ì œê±°
            final_content = re.sub(
                rf'href="[/\-]+{re.escape(token)}"',
                f'href="{token}"',
                final_content
            )
            # íŒ¨í„´ 3: í† í° ì•ì— ì–´ë–¤ ë¬¸ìë“  ìˆìœ¼ë©´ ì œê±°
            final_content = re.sub(
                rf'href="[^"]*?{re.escape(token)}"',
                f'href="{token}"',
                final_content
            )


        # [í•µì‹¬ ë‹¨ê³„ 2] í† í°ì„ ì‹¤ì œ URLë¡œ ì •í™•íˆ ì¹˜í™˜
        for token, real_url in links_mapping.items():
            # í† í°ë§Œ ì •í™•íˆ ë§¤ì¹­í•˜ì—¬ ì¹˜í™˜
            final_content = final_content.replace(f'href="{token}"', f'href="{real_url}"')

        post_data['content'] = final_content


        # [ë””ë²„ê·¸] ì¹˜í™˜ ì „í›„ ë¹„êµ
        print("\n=== ë””ë²„ê·¸: ë§í¬ ì¹˜í™˜ ê²€ì¦ ===")
        for token, real_url in links_mapping.items():
            # í† í°ì´ ë‚¨ì•„ìˆëŠ”ì§€ í™•ì¸
            if token in final_content:
                print(f"âš ï¸  ë¯¸ì¹˜í™˜ í† í° ë°œê²¬: {token}")

            # ì‹¤ì œ URLì´ ì œëŒ€ë¡œ ë“¤ì–´ê°”ëŠ”ì§€ í™•ì¸
            matches = re.findall(rf'href="([^"]*{re.escape(real_url.split("/")[-1] if "/" in real_url else real_url)}[^"]*)"', final_content)
            print(f"âœ“ {token} â†’ {real_url}")
            for match in matches[:2]:
                print(f"  â†’ {match}")


        # [í•µì‹¬ ë‹¨ê³„ 3] ìµœì¢… ë³¸ë¬¸ ë¬¼ë¦¬ì  ì •ì œ
        post_data['content'] = self.clean_content(post_data['content'])


        # [ìµœì¢… ê²€ì¦] ê¹¨ì§„ URL íŒ¨í„´ ì²´í¬
        print("\n=== ìµœì¢… URL ê²€ì¦ ===")
        broken_patterns = re.findall(r'href="([^"]*(?:/\.[a-z]{2,}/|/[^/]*\.[a-z]{2,}(?:/|$))[^"]*)"', post_data['content'])
        if broken_patterns:
            print(f"âš ï¸  ì˜ì‹¬ìŠ¤ëŸ¬ìš´ URL íŒ¨í„´ {len(broken_patterns)}ê°œ ë°œê²¬:")
            for pattern in broken_patterns[:5]:
                print(f"  - {pattern}")
        else:
            print("âœ“ ëª¨ë“  URLì´ ì •ìƒì…ë‹ˆë‹¤")


        img_id = self.upload_media(self.generate_image(post_data['title'], post_data['excerpt']))
        tag_ids = self.get_or_create_tag_ids(post_data.get('tags', ''))


        payload = {
            "title": post_data['title'],
            "content": post_data['content'],
            "excerpt": post_data['excerpt'],
            "status": "publish",
            "featured_media": img_id if img_id else 0,
            "tags": tag_ids
        }

        res = requests.post(f"{CONFIG['WP_URL']}/wp-json/wp/v2/posts", headers={"Authorization": f"Basic {self.auth}", "Content-Type": "application/json"}, json=payload, timeout=60)
        if res.status_code == 201:
            print(f"\nğŸ‰ ë°œí–‰ ì„±ê³µ: {post_data['title']}")
            print(f"ğŸ”— URL: {res.json().get('link', 'N/A')}")
        else:
            print(f"\nâŒ ë°œí–‰ ì‹¤íŒ¨: {res.status_code}")
            print(f"ì˜¤ë¥˜ ë‚´ìš©: {res.text[:500]}")


if __name__ == "__main__":
    WordPressAutoPoster().generate_post()
